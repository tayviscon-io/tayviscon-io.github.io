---
author: tyomych-tovkach
title: "Apache Kafka"
date: 2025-02-11 20:00:00 +0300
categories: [Курсы, Разработка]
tags: [Apache Kafka]
description: Курс посвящен изучению основ работы с Apache Kafka с целью
  пониманию принципов работы с платформой для передачи и обработки событий в реальном времени.
media_subpath: /assets/courses/development/apache-kafka
image:
  path: apache-kafka-logo.svg
  alt: "Apache Kafka: Логотип курса"
---

_В рамках данного курса, мы постараемся изучить все аспекты Apache Kafka, чтобы
уверенно использовать данную платформу для передачи и обработки событий реального времени,
а также сделать процессы отслеживания метрик и настройки отказоустойчивого кластера понятным каждому._

Всем привет, кто изучает "Apache Kafka"!

В рамках курса планируется рассмотреть следующие темы:

1. Введение
2. Основы технологии
3. Установка и работа с кластером из одного брокера
4. Клиентские библиотеки
5. Отказоустойчивость кластера в рамках одного дата-цента
6. Работа с распределенным кластером
7. Мониторинг
8. Анализ производительности
9. Поддержка работоспособности кластера и траблшуттинг
10. Развертывание кластер на продакшн 

> Данный курс будет пополняться новыми главами по мере получения новых знаний.
> Вы можете предлагать свои темы для рассмотрения, а также
> создавать merge-request'ы с целью улучшения, как отдельной главы, так и курса в целом.
{: .prompt-info }

## ВВЕДЕНИЕ

### История создания

![Apache Kafka: История создания](apache-kafka-history.svg)
_Apache Kafka: История создания_

Изначально Apache Kafka была разработана в компании **LinkedIn** _Джеем Крепсом_, _Нией Нархид_ и _Чжаном Рао_ для 
внутреннего использования, так как была потребность в инструменте,
который мог бы обрабатывать огромные потоки данных между различными частями их внутренней архитектуры,
однако существовавшие на тот момент решения их не устроили и они решили реализовать свой проект,
принимая во внимание все плюсы и минусы существующих решений.

> Джей Крепс решил, что было бы здорово назвать проект оптимизированный для записи
> в честь какого-нибудь известного писателя (Франца Кафки).
{: .prompt-info }

Важным этапом стал 2011 год, когда разработчики открыли исходный код системы под лицензией Apache и проект бы принят в 
Apache Инкубатор (некий шлюз для проектов с открытым исходным кодом,
которые должны стать полноценными проектами Apache Software Foundation) и успешно был выпушен в 2012 году.
Однако уже в 2014 основные авторы покидают LinkedIn и основывают компанию Confluent для коммерциализации проекта.
В 2021 году Confluent выходит на IPO и достигает по его результатам капитализацию в $10 млрд.

Первый прототип проекта был разработан Крепсом за рождественские праздники, а целевая версия всего за 3 месяца,
однако, как мы видим, уже более 10 лет проект активно развивается,
что мы можем увидеть по [GitHub-репозиторию](https://github.com/apache/kafka) данного проекта.

### Что такое Apache Kafka?

**Apache Kafka** - это распределенный брокер сообщений, работающий в стриминговом режиме,
который благодаря своей архитектуре может выступать в роли распределенного лога, базы данных, системы очередей
или даже платформой для потоковой обработки данных. Так что использование данного инструмента напрямую зависит
от вашей задачи!

Чаще всего для того, чтобы объяснить "Что такое Apache Kafka?" используют термины:
_Распределенное key-value хранилище_, _Распределенный Commit Log_.

![Apache Kafka: Основы взаимодействия](apache-kafka-producer-consumer-intro.svg)
_Apache Kafka: Основы взаимодействия_

Основная концепция взаимодействия с Apache Kafka очень проста:
мы можем публиковать (_produce_) различные потоки данных (сообщения, метрики, логи, изображения),
а также подписываться (_consume_) на получение этой информации.

К преимуществам использования Apache Kafka можно отнести следующие аспекты:

- Эффективная работа при больших объемах информации;
- Отличная горизонтальная масштабируемость;
- Хранение данных на диске;
- Высокая отказоустойчивость;
- Доступность.

Для того чтобы нам разговаривать на одном языке давайте осветим несколько терминов:

Распределенная система хранения данных
: это инфраструктура, которая может разделять данные между несколькими физическими сервера
и часто между несколькими центрами обработки данных, но представляемая для пользователя в виде единого целого.

Горизонтальное масштабирование
: техника, которая позволяет решить две задачи: выдерживать большую нагрузку и повысить отказоустойчивость системы,
за счет добавления в систему дополнительных машин, вместо увеличения мощностей одной. 

Отказоустойчивость
: свойство технической системы сохранять свою работоспособность после отказа одной или нескольких её составных частей.

Лог
: это упорядоченная по времени _append-only_ структура данных.

Однако помимо базовой функции хранения и передачи данных у Kafka есть поддержка потоковой обработки данных,
которые обеспечиваются за счет нативного Kafka Streams API или внешних фреймворков (например: _Apache Flink_).
Благодаря такому подходу, в отличие от традиционной пакетной обработки (_batching_), можно достигнуть высокой
скорости обработки за счет того, что данные обрабатываются сразу, как только они попадают в Kafka.

![Apache Kafka: Основы потоковой обработки](apache-kafka-stream-intro.svg)
_Apache Kafka: Основы потоковой обработки_

Под потоковой обработкой данных мы понимаем получение на входе, непрерывно пополняющегося, потока данных,
а затем такую же непрерывную обработку этих данных и подачу полученного результата в другой топик.

Стоит также отметить развитую экосистему инструментов вокруг Apache Kafka.
Например, фреймворк _Kafka Connect_ позволяет налаживать интеграцию между Kafka и другими системами в считанные минуты,
используя только конфигурационные файлы.

![Apache Kafka: Основы работы с инструментом Kafka Connect](apache-kafka-connect-intro.svg)
_Apache Kafka: Основы работы с инструментом Kafka Connect_

Таким образом, Apache Kafka это **распределенное**, **отказоустойчивое**, **горизонтально масштабируемое хранилище**,
основной структурой данных в котором является **append-only лог**, которое поддерживает потоковую обработку данных
и имеет развитую экосистему коннекторов для интеграции с базами данных и другими хранилищами.

### Почему стоит выбрать Apache Kafka?

На самом деле существует большое количество publish/subscribe систем, но есть рад факторов,
которые выделяют Apache Kafka на рынке конкурентов:

- Возможность работы с большим количеством продюсеров вне зависимости от
того используют ли эти продюсеры один топик или несколько,
что делает технологию идеальной для агрегирования данных из внешних систем;
- Несколько консьюмеров могут читать поток любой поток сообщений не мешая друг-друг, что исключает кейс,
когда сообщений полученное одним клиентом становиться недоступным для других.
Несколько потребителей могут использовать поток в качестве одной консьюмер группы
и совместно его использовать перераспределяю нагрузку между друг-другом, гарантируя при этом,
что вся группа обработает весь поток только один раз;
- Все сообщения хранятся на диске и имеют настраиваемые правила хранения,
что позволяет консьюмерам перечитать данные из прошлого;
- Положение консьюмеров также сохраняется на диске,
что позволяет беспрепятственно отключаться-включаться не теряя при этом события;
- Может обрабатывать огромное количество сообщений,
так как консьюмеров, продюсеров и брокеров можно масштабировать горизонтально;
- Развитость экосистемы (_Kafka Connect_, _Kafka Streams_).

### Примеры использования

Одним из основных способов использования Apache Kafka является ее применение в роли брокера сообщений
для обеспечения межсервисного взаимодействия. Такой подход позволяется развязать/распределить части приложения 
и обеспечить между ними надежную асинхронную коммуникацию.

Ещё одним популярным паттерном при использовании Apache Kafka является обработка и отслеживание действий пользователей
(так называемые _**Кликстримы**_ - _это серия последовательных действий, которые совершает пользователя на сайте_).

Apache Kafka можно также использовать в качестве системы очередей, но стоит отметить,
что в основе Kafka лежит семантика топиков, которая отличается от семантики очередей.

Другой способ применения Apache Kafka - журналирование и сбор метрик: мы использовать Kafka,
как буфер перед другими системами для их агрегации и доставки в финальные хранилища
для долговременного хранения и визуализации.

Зная, что в основе Apache Kafka лежит лог,
то можно использовать ее для захвата изменений из одних систем передачи в другие.

В целом, Apache Kafka может выступать даже в роли центрального хранилища всей организации. Данные из всех БД, например, 
могут сливаться в Kafka и затем использоваться другими системами.

### Заключение

В данной главе мы попытались понять: "Что такое Apache Kafka?", "Зачем она нужна?" и "Как можно ее использовать?".
По итогу определили:

- Apache Kafka - быстрая, надежная технология с богатой экосистемой и активно растущим комьюнити;
- Kafka может быть использована для решения разнообразных задач;
- Спрос на специалистов, знающих эту технологию, продолжает расти!

> Глава завершена!
> (комьюнити может редактировать/дополнять ее по мере необходимости)
{: .prompt-info }

## ОСНОВЫ ТЕХНОЛОГИИ

В данной главе мы собираемся немного углубиться в устройство Apache Kafka.
Начнем мы с того, что разберемся в том, чем же Apache Kafka отличается от популярных система обмена сообщениями.
Затем постараемся понять, как Kafka хранит данные и обеспечивает гарантию сохранности. И завершим главу тем,
что рассмотрим как записываются и читаются данные.

### Apache Kafka VS Queues

Начнем наше погружение в основы технологии с того,
что сравним Apache Kafka с популярными сервисами очередей (например, _RabbitMQ_, _Amazon SQS_).

Системы очередей чаще всего состоят из трех базовых компонентов: сервера, продюсеров, консьюмеров.
Задача продюсеров - отправить сообщение в какую-нибудь именованную очередь,
которая заранее сконфигурирована администратором на сервере,
а коньсьюмеров - считать эти сообщения по мере их появления.

> В контексте web-приложений очереди часто используются для отложенной обработки событий
> или в качестве временного буфера перед другими сервисами,
> что позволяет обезопасить сервисы от неожиданных всплесков нагрузки.
{: .prompt-tip }

![Apache Kafka: Модели запросов консьюмеров](apache-kafka-request-models.svg)
_Apache Kafka: Модели запросов консьюмеров_

Консьюмеры получают данные от сервера, используя две разных модели запросов в зависимости от технологии.

Первая - _pull_-модель: консьюмеры сами отправляют запроса на сервер раз в N секунд
для получения новой порции сообщений.
Стоит отметить, что при таком подходе, клиенты эффективно могут контролировать свою нагрузку,
а также именно pull-модель позволяет эффективно группировать сообщений в пачки (_batch_), 
благодаря чему достигается лучшая пропускная способность. Однако есть и минусы такой модели:
потенциальная разбалансированность нагрузки между различными консьюмерами, а также высокая задержка обработки данных.

Вторая - _push_-модель: сервер сам делает запрос к клиенту, посылая новую порцию данных. По такой модели, например,
работает RabbitMQ. Такой подход снижает задержку обработки сообщений по сравнению с pull-моделью и
позволяет эффективно балансировать распределение сообщений по консьюмерам.
Но для предотвращения перегрузки консьюмеров, в случае с RabbitMQ, клиентам приходится использовать функционал QoS, 
выставляя `prefetch_count`.

В боевых системах, чаще всего, приложение пишет и читает из очереди
с помощью нескольких инстансов продюсеров и консьюмеров для эффективного распределения нагрузки.

![Apache Kafka: Жизненный цикл сообщения в системах очередей](apache-kafka-queue-messsage-lifecycle.svg)
_Apache Kafka: Жизненный цикл сообщения в системах очередей_

Типичный жизненный цикл сообщения в системах очередей выглядит следующим образом:

1. Отправка продюсером сообщения на сервер;
2. Запрос консьюмером сообщения и его уникальных идентификатор сервера.
(В это время сервер помечает сообщение статусом _inflight_.
Сообщения в этом статусе хранятся на сервере, но не доступны другим консьюмерам.
Таймаут этого состояния обычно регулируется специальной настройкой.);
3. Далее консьюмер обрабатывает это сообщение следуя некой бизнес-логике.
4. Консьмер отправляет _ack/nack_ запрос на сервер, используя уникальный идентификатор, полученный ранее.
(Таким образом консьюмер подтверждает получение запроса или сигнализирует об ошибке).
В случе успешной обработки сообщение удалится на сервере,
в ином случае или по истечении таймаута статуса inflight сообщение помещается обратно на сервер
для отправки другому консьюмеру.

Давай те же наконец рассмотрим фундаментальные отличия Apache Kafka от сервисов очередей.
Так же как и сервисы очередей Apache Kafka условно состоит из трех базовых компонентов:
сервера (зачастую называют брокером), продюсера и консьюмера, использующего pull-модель.
Однако же главным отличием кафки от очередей кроется в том,
как сообщения хранятся на брокере и как потребляются комнсьюмерами. 
Сообщения в Apache Kafka **не удаляются** по мере их обработки консьюмерами.
Благодаря этому одни и те же сообщения могут быть обработаны **сколько угодно раз**
совершенно разными консьюмерами и в разных контекстах.

Давайте посмотрим на то, как Apache Kafka и традиционные системы очередей решают одну и ту же проблему:

![Apache Kafka: Традиционная система очередей в действии](apache-kafka-queue-server-solution.svg)
_Apache Kafka: Традиционная система очередей в действии_

Начнем с традиционной системы очередей и представим, что у нас есть одной какое-то событие,
о котором хотят знать различные сервисы.
Для того чтобы доставить сообщение всем сервиса одновременно в случае с RabbitMQ
нам следовало бы воспользоваться функциональностью `fanout`, однако при необходимости подключения нового сервиса,
придется конфигурировать новые очереди. 


![Apache Kafka: Брокер Kafka в действии](apache-kafka-kafka-broker-solution.svg)
_Apache Kafka: Брокер Kafka в действии_

По сравнению с RabbitMQ, Apache Kafka делает эту задачу еще более простой.
Нам нужно будет послать сообщение только один раз, а все сервисы сами прочитают его по мере необходимости.
Apache Kafka также позволяет с легкостью подключать новые сервисы без какого-либо
реконфигурирования сервера или добавления новых очередей.
Кроме того, так как Apache Kafka не удаляет сообщения по мере их потребления консьюмерами, следовательно,
эти данные могут обрабатываться заново, чтоб может быть очень полезно после восстановления после сбоев
или тестирования и верификации работы новых консьюмеров.

> Глава завершена!
> (комьюнити может редактировать/дополнять ее по мере необходимости)
{: .prompt-info }

### Структура данных

Возможно вы уже задумались над тем,
почему консьюмеры не читают одни и те же сообщения раз за разом, если сообщения в Apache Kafka не удаляются!
Для того чтобы ответить на этот вопрос, нам стоит разобраться во внутренней структуре Apache Kafka и понять,
как в ней хранятся сообщения.

Каждое сообщение Apache Kafka состоит из следующих компонентов:

- **Key**: "Tayviscon IO";
- **Value**: "Apache Kafka Course Creation";
- **Timestamp**: "Feb. 26, 2025 at 8:39 p.m." (CreateTime, LogAppendTime);
- **Headers**: [{"header_key":"header_value"}].

Сообщения в Apache Kafka организованы и хранятся в так называемых Топиках (Topics),
а каждый топик, в свою очередь, состоит из 1-й и более партиций (Partition),
распределенных между брокерами внутри одного кластера.

> Подобная распределенность важна для горизонтального масштабирования кластера,
> так как она позволяет клиентам писать и читать сообщения из нескольких брокеров одновременно.
{: .prompt-tip } 

При добавлении нового сообщения в топик оно записывается в одну из партиций этого топика.
Сообщения с одинаковыми ключами (_key_) записываются в одну и ту же партицию - MurmurHash,
тем самым гарантируя очередность порядка записи и чтения в рамках одной партиции. _Если ключ отсутствует - RoundRobin_.

Для гарантии сохранность данных каждая партиция может быть реплицирована N раз, где _N_ - _replication-factor_.
Таким образом гарантируется наличие нескольких копий сообщения, хранящегося на разных брокерах.

![Apache Kafka: Разделение топика на партиции](apache-kafka-topic-partition-relation.svg)
_Apache Kafka: Разделение топика на партиции_

Мы должны знать, что на самом деле у каждой партии есть свой лидер (_Leader_) или брокер, который работает с клиентами.
Именно лидер принимает сообщения от продюсеров и, в общем случае, отдает сообщения консьюмерам.
К лидеру осуществляют запросы фолловеры (_Follower_), то есть брокеры, которые хранят реплику все данных партиции.
Для того чтобы понять, кто является лидером партиции, клиенты делают запрос, чтобы получить метаданные от брокера.
Стоит отметить, что они могут подключаться к любому брокеру в кластере, чтобы сделать этот запрос.

![Apache Kafka: Взаимодействие Leader'ов и Follower'ов](apache-kafka-leader-follower-relation.svg)
_Apache Kafka: Взаимодействие Leader'ов и Follower'ов_

Как мы уже знаем, основная структура Apache Kafka это распределенный, реплицируемый лог и на самом деле каждая партиция
и является тем самым логом, который хранится на диске.
Каждое новое сообщение, отправленное продюсеров в партицию, сохраняется в голову этого лога и получает свой уникальный
_offset_ (монотонно возрастающий 64-bit unsigned int, который устанавливается самим брокером).

Сообщения из Apache Kafka не удаляются из лога после того, как были вычитаны консьюмером.
Вместо этого, мы, как администраторы,
можем контролировать минимальное время в течении которого сообщения будут гарантировано хранится на брокере.

- `retention.ms` - минимальное время хранения сообщений;
- `retention.bytes` - максимальный размер партиции.

Стоит отметить, что длительность хранения сообщений не влияет на производительность системы,
так что вы можете храниться сообщения в Apache Kafka днями, неделями, месяцами или даже годами.

## УСТАНОВКА И РАБОТА С КЛАСТЕРОМ ИЗ ОДНОГО БРОКЕРА

> Глава находится на этапе разработки!
{: .prompt-danger }

## КЛИЕНТСКИЕ БИБЛИОТЕКИ

> Глава находится на этапе разработки!
{: .prompt-danger }

## ОТКАЗОУСТОЙЧИВОТЬ КЛАСТЕР В РАМКАХ ОДНОГО ДАТА-ЦЕНТРА

> Глава находится на этапе разработки!
{: .prompt-danger }

## РАБОТА С РАСПРЕДЕЛЕННЫМ КЛАСТЕРОМ

> Глава находится на этапе разработки!
{: .prompt-danger }

## МОНИТОРИНГ

> Глава находится на этапе разработки!
{: .prompt-danger }

## АНАЛИЗ ПРОИЗВОДИТЕЛЬНОСТИ

> Глава находится на этапе разработки!
{: .prompt-danger }

## ПОДДЕРЖКА РАБОТОСПОСОБНОСТИ КЛАСТЕРА И ТАРБЛШУТТИНГ

> Глава находится на этапе разработки!
{: .prompt-danger }

## РАЗВЕРТЫВАНИЕ КЛАСТЕР НА ПРОДАКШН

> Глава находится на этапе разработки!
{: .prompt-danger }
